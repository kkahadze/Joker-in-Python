{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv('../data/20000_games_2023-08-06 15:55:12.860824.csv')\n",
    "\n",
    "# Select columns you want to use for prediction\n",
    "selected_columns = ['dealt', 'first_to_play', 'dealer', 'wild_suit',\n",
    "                    'player0desired', 'player1desired', 'player2desired', 'player3desired',\n",
    "                    'hand1', 'hand2', 'hand3', 'hand4', 'hand5', 'hand6', 'hand7',\n",
    "                    'hand8', 'hand9', 'deciding_player']\n",
    "\n",
    "X = df[selected_columns]\n",
    "y = df['desired']\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train.to_numpy())\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Initialize the model and define loss and optimizer\n",
    "model = Net(X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLoss: 1.091297\n",
      "Train Epoch: 10 \tLoss: 1.090370\n",
      "Train Epoch: 20 \tLoss: 1.089465\n",
      "Train Epoch: 30 \tLoss: 1.088581\n",
      "Train Epoch: 40 \tLoss: 1.087717\n",
      "Train Epoch: 50 \tLoss: 1.086872\n",
      "Train Epoch: 60 \tLoss: 1.086046\n",
      "Train Epoch: 70 \tLoss: 1.085236\n",
      "Train Epoch: 80 \tLoss: 1.084443\n",
      "Train Epoch: 90 \tLoss: 1.083666\n",
      "Train Epoch: 100 \tLoss: 1.082903\n",
      "Train Epoch: 110 \tLoss: 1.082155\n",
      "Train Epoch: 120 \tLoss: 1.081421\n",
      "Train Epoch: 130 \tLoss: 1.080700\n",
      "Train Epoch: 140 \tLoss: 1.079992\n",
      "Train Epoch: 150 \tLoss: 1.079295\n",
      "Train Epoch: 160 \tLoss: 1.078611\n",
      "Train Epoch: 170 \tLoss: 1.077937\n",
      "Train Epoch: 180 \tLoss: 1.077273\n",
      "Train Epoch: 190 \tLoss: 1.076621\n",
      "Train Epoch: 200 \tLoss: 1.075978\n",
      "Train Epoch: 210 \tLoss: 1.075345\n",
      "Train Epoch: 220 \tLoss: 1.074721\n",
      "Train Epoch: 230 \tLoss: 1.074107\n",
      "Train Epoch: 240 \tLoss: 1.073501\n",
      "Train Epoch: 250 \tLoss: 1.072902\n",
      "Train Epoch: 260 \tLoss: 1.072312\n",
      "Train Epoch: 270 \tLoss: 1.071730\n",
      "Train Epoch: 280 \tLoss: 1.071155\n",
      "Train Epoch: 290 \tLoss: 1.070588\n",
      "Train Epoch: 300 \tLoss: 1.070027\n",
      "Train Epoch: 310 \tLoss: 1.069473\n",
      "Train Epoch: 320 \tLoss: 1.068926\n",
      "Train Epoch: 330 \tLoss: 1.068386\n",
      "Train Epoch: 340 \tLoss: 1.067853\n",
      "Train Epoch: 350 \tLoss: 1.067326\n",
      "Train Epoch: 360 \tLoss: 1.066805\n",
      "Train Epoch: 370 \tLoss: 1.066291\n",
      "Train Epoch: 380 \tLoss: 1.065782\n",
      "Train Epoch: 390 \tLoss: 1.065280\n",
      "Train Epoch: 400 \tLoss: 1.064785\n",
      "Train Epoch: 410 \tLoss: 1.064294\n",
      "Train Epoch: 420 \tLoss: 1.063808\n",
      "Train Epoch: 430 \tLoss: 1.063328\n",
      "Train Epoch: 440 \tLoss: 1.062854\n",
      "Train Epoch: 450 \tLoss: 1.062385\n",
      "Train Epoch: 460 \tLoss: 1.061920\n",
      "Train Epoch: 470 \tLoss: 1.061461\n",
      "Train Epoch: 480 \tLoss: 1.061006\n",
      "Train Epoch: 490 \tLoss: 1.060556\n",
      "Train Epoch: 500 \tLoss: 1.060110\n",
      "Train Epoch: 510 \tLoss: 1.059668\n",
      "Train Epoch: 520 \tLoss: 1.059230\n",
      "Train Epoch: 530 \tLoss: 1.058797\n",
      "Train Epoch: 540 \tLoss: 1.058368\n",
      "Train Epoch: 550 \tLoss: 1.057943\n",
      "Train Epoch: 560 \tLoss: 1.057521\n",
      "Train Epoch: 570 \tLoss: 1.057104\n",
      "Train Epoch: 580 \tLoss: 1.056691\n",
      "Train Epoch: 590 \tLoss: 1.056282\n",
      "Train Epoch: 600 \tLoss: 1.055876\n",
      "Train Epoch: 610 \tLoss: 1.055475\n",
      "Train Epoch: 620 \tLoss: 1.055077\n",
      "Train Epoch: 630 \tLoss: 1.054683\n",
      "Train Epoch: 640 \tLoss: 1.054292\n",
      "Train Epoch: 650 \tLoss: 1.053904\n",
      "Train Epoch: 660 \tLoss: 1.053520\n",
      "Train Epoch: 670 \tLoss: 1.053139\n",
      "Train Epoch: 680 \tLoss: 1.052761\n",
      "Train Epoch: 690 \tLoss: 1.052386\n",
      "Train Epoch: 700 \tLoss: 1.052013\n",
      "Train Epoch: 710 \tLoss: 1.051644\n",
      "Train Epoch: 720 \tLoss: 1.051278\n",
      "Train Epoch: 730 \tLoss: 1.050915\n",
      "Train Epoch: 740 \tLoss: 1.050554\n",
      "Train Epoch: 750 \tLoss: 1.050195\n",
      "Train Epoch: 760 \tLoss: 1.049840\n",
      "Train Epoch: 770 \tLoss: 1.049487\n",
      "Train Epoch: 780 \tLoss: 1.049138\n",
      "Train Epoch: 790 \tLoss: 1.048791\n",
      "Train Epoch: 800 \tLoss: 1.048447\n",
      "Train Epoch: 810 \tLoss: 1.048106\n",
      "Train Epoch: 820 \tLoss: 1.047767\n",
      "Train Epoch: 830 \tLoss: 1.047430\n",
      "Train Epoch: 840 \tLoss: 1.047096\n",
      "Train Epoch: 850 \tLoss: 1.046765\n",
      "Train Epoch: 860 \tLoss: 1.046437\n",
      "Train Epoch: 870 \tLoss: 1.046111\n",
      "Train Epoch: 880 \tLoss: 1.045787\n",
      "Train Epoch: 890 \tLoss: 1.045466\n",
      "Train Epoch: 900 \tLoss: 1.045147\n",
      "Train Epoch: 910 \tLoss: 1.044830\n",
      "Train Epoch: 920 \tLoss: 1.044514\n",
      "Train Epoch: 930 \tLoss: 1.044201\n",
      "Train Epoch: 940 \tLoss: 1.043891\n",
      "Train Epoch: 950 \tLoss: 1.043582\n",
      "Train Epoch: 960 \tLoss: 1.043276\n",
      "Train Epoch: 970 \tLoss: 1.042972\n",
      "Train Epoch: 980 \tLoss: 1.042670\n",
      "Train Epoch: 990 \tLoss: 1.042370\n",
      "Train Epoch: 1000 \tLoss: 1.042072\n",
      "Train Epoch: 1010 \tLoss: 1.041775\n",
      "Train Epoch: 1020 \tLoss: 1.041479\n",
      "Train Epoch: 1030 \tLoss: 1.041185\n",
      "Train Epoch: 1040 \tLoss: 1.040893\n",
      "Train Epoch: 1050 \tLoss: 1.040602\n",
      "Train Epoch: 1060 \tLoss: 1.040312\n",
      "Train Epoch: 1070 \tLoss: 1.040024\n",
      "Train Epoch: 1080 \tLoss: 1.039737\n",
      "Train Epoch: 1090 \tLoss: 1.039453\n",
      "Train Epoch: 1100 \tLoss: 1.039170\n",
      "Train Epoch: 1110 \tLoss: 1.038888\n",
      "Train Epoch: 1120 \tLoss: 1.038609\n",
      "Train Epoch: 1130 \tLoss: 1.038330\n",
      "Train Epoch: 1140 \tLoss: 1.038053\n",
      "Train Epoch: 1150 \tLoss: 1.037777\n",
      "Train Epoch: 1160 \tLoss: 1.037502\n",
      "Train Epoch: 1170 \tLoss: 1.037229\n",
      "Train Epoch: 1180 \tLoss: 1.036956\n",
      "Train Epoch: 1190 \tLoss: 1.036685\n",
      "Train Epoch: 1200 \tLoss: 1.036416\n",
      "Train Epoch: 1210 \tLoss: 1.036147\n",
      "Train Epoch: 1220 \tLoss: 1.035880\n",
      "Train Epoch: 1230 \tLoss: 1.035613\n",
      "Train Epoch: 1240 \tLoss: 1.035348\n",
      "Train Epoch: 1250 \tLoss: 1.035084\n",
      "Train Epoch: 1260 \tLoss: 1.034821\n",
      "Train Epoch: 1270 \tLoss: 1.034560\n",
      "Train Epoch: 1280 \tLoss: 1.034300\n",
      "Train Epoch: 1290 \tLoss: 1.034041\n",
      "Train Epoch: 1300 \tLoss: 1.033785\n",
      "Train Epoch: 1310 \tLoss: 1.033529\n",
      "Train Epoch: 1320 \tLoss: 1.033274\n",
      "Train Epoch: 1330 \tLoss: 1.033021\n",
      "Train Epoch: 1340 \tLoss: 1.032768\n",
      "Train Epoch: 1350 \tLoss: 1.032517\n",
      "Train Epoch: 1360 \tLoss: 1.032268\n",
      "Train Epoch: 1370 \tLoss: 1.032020\n",
      "Train Epoch: 1380 \tLoss: 1.031773\n",
      "Train Epoch: 1390 \tLoss: 1.031527\n",
      "Train Epoch: 1400 \tLoss: 1.031282\n",
      "Train Epoch: 1410 \tLoss: 1.031039\n",
      "Train Epoch: 1420 \tLoss: 1.030797\n",
      "Train Epoch: 1430 \tLoss: 1.030555\n",
      "Train Epoch: 1440 \tLoss: 1.030315\n",
      "Train Epoch: 1450 \tLoss: 1.030076\n",
      "Train Epoch: 1460 \tLoss: 1.029838\n",
      "Train Epoch: 1470 \tLoss: 1.029601\n",
      "Train Epoch: 1480 \tLoss: 1.029365\n",
      "Train Epoch: 1490 \tLoss: 1.029130\n",
      "Train Epoch: 1500 \tLoss: 1.028897\n",
      "Train Epoch: 1510 \tLoss: 1.028664\n",
      "Train Epoch: 1520 \tLoss: 1.028433\n",
      "Train Epoch: 1530 \tLoss: 1.028202\n",
      "Train Epoch: 1540 \tLoss: 1.027972\n",
      "Train Epoch: 1550 \tLoss: 1.027743\n",
      "Train Epoch: 1560 \tLoss: 1.027515\n",
      "Train Epoch: 1570 \tLoss: 1.027287\n",
      "Train Epoch: 1580 \tLoss: 1.027061\n",
      "Train Epoch: 1590 \tLoss: 1.026836\n",
      "Train Epoch: 1600 \tLoss: 1.026612\n",
      "Train Epoch: 1610 \tLoss: 1.026389\n",
      "Train Epoch: 1620 \tLoss: 1.026167\n",
      "Train Epoch: 1630 \tLoss: 1.025946\n",
      "Train Epoch: 1640 \tLoss: 1.025726\n",
      "Train Epoch: 1650 \tLoss: 1.025507\n",
      "Train Epoch: 1660 \tLoss: 1.025288\n",
      "Train Epoch: 1670 \tLoss: 1.025071\n",
      "Train Epoch: 1680 \tLoss: 1.024854\n",
      "Train Epoch: 1690 \tLoss: 1.024638\n",
      "Train Epoch: 1700 \tLoss: 1.024423\n",
      "Train Epoch: 1710 \tLoss: 1.024209\n",
      "Train Epoch: 1720 \tLoss: 1.023996\n",
      "Train Epoch: 1730 \tLoss: 1.023783\n",
      "Train Epoch: 1740 \tLoss: 1.023571\n",
      "Train Epoch: 1750 \tLoss: 1.023360\n",
      "Train Epoch: 1760 \tLoss: 1.023149\n",
      "Train Epoch: 1770 \tLoss: 1.022938\n",
      "Train Epoch: 1780 \tLoss: 1.022728\n",
      "Train Epoch: 1790 \tLoss: 1.022519\n",
      "Train Epoch: 1800 \tLoss: 1.022311\n",
      "Train Epoch: 1810 \tLoss: 1.022104\n",
      "Train Epoch: 1820 \tLoss: 1.021897\n",
      "Train Epoch: 1830 \tLoss: 1.021692\n",
      "Train Epoch: 1840 \tLoss: 1.021487\n",
      "Train Epoch: 1850 \tLoss: 1.021282\n",
      "Train Epoch: 1860 \tLoss: 1.021078\n",
      "Train Epoch: 1870 \tLoss: 1.020874\n",
      "Train Epoch: 1880 \tLoss: 1.020670\n",
      "Train Epoch: 1890 \tLoss: 1.020468\n",
      "Train Epoch: 1900 \tLoss: 1.020266\n",
      "Train Epoch: 1910 \tLoss: 1.020065\n",
      "Train Epoch: 1920 \tLoss: 1.019864\n",
      "Train Epoch: 1930 \tLoss: 1.019663\n",
      "Train Epoch: 1940 \tLoss: 1.019464\n",
      "Train Epoch: 1950 \tLoss: 1.019265\n",
      "Train Epoch: 1960 \tLoss: 1.019066\n",
      "Train Epoch: 1970 \tLoss: 1.018869\n",
      "Train Epoch: 1980 \tLoss: 1.018672\n",
      "Train Epoch: 1990 \tLoss: 1.018477\n",
      "Train Epoch: 2000 \tLoss: 1.018282\n",
      "Train Epoch: 2010 \tLoss: 1.018088\n",
      "Train Epoch: 2020 \tLoss: 1.017894\n",
      "Train Epoch: 2030 \tLoss: 1.017701\n",
      "Train Epoch: 2040 \tLoss: 1.017507\n",
      "Train Epoch: 2050 \tLoss: 1.017315\n",
      "Train Epoch: 2060 \tLoss: 1.017123\n",
      "Train Epoch: 2070 \tLoss: 1.016931\n",
      "Train Epoch: 2080 \tLoss: 1.016739\n",
      "Train Epoch: 2090 \tLoss: 1.016548\n",
      "Train Epoch: 2100 \tLoss: 1.016358\n",
      "Train Epoch: 2110 \tLoss: 1.016168\n",
      "Train Epoch: 2120 \tLoss: 1.015978\n",
      "Train Epoch: 2130 \tLoss: 1.015789\n",
      "Train Epoch: 2140 \tLoss: 1.015600\n",
      "Train Epoch: 2150 \tLoss: 1.015412\n",
      "Train Epoch: 2160 \tLoss: 1.015224\n",
      "Train Epoch: 2170 \tLoss: 1.015036\n",
      "Train Epoch: 2180 \tLoss: 1.014849\n",
      "Train Epoch: 2190 \tLoss: 1.014663\n",
      "Train Epoch: 2200 \tLoss: 1.014477\n",
      "Train Epoch: 2210 \tLoss: 1.014291\n",
      "Train Epoch: 2220 \tLoss: 1.014105\n",
      "Train Epoch: 2230 \tLoss: 1.013920\n",
      "Train Epoch: 2240 \tLoss: 1.013736\n",
      "Train Epoch: 2250 \tLoss: 1.013553\n",
      "Train Epoch: 2260 \tLoss: 1.013369\n",
      "Train Epoch: 2270 \tLoss: 1.013187\n",
      "Train Epoch: 2280 \tLoss: 1.013005\n",
      "Train Epoch: 2290 \tLoss: 1.012823\n",
      "Train Epoch: 2300 \tLoss: 1.012642\n",
      "Train Epoch: 2310 \tLoss: 1.012462\n",
      "Train Epoch: 2320 \tLoss: 1.012283\n",
      "Train Epoch: 2330 \tLoss: 1.012104\n",
      "Train Epoch: 2340 \tLoss: 1.011925\n",
      "Train Epoch: 2350 \tLoss: 1.011747\n",
      "Train Epoch: 2360 \tLoss: 1.011569\n",
      "Train Epoch: 2370 \tLoss: 1.011390\n",
      "Train Epoch: 2380 \tLoss: 1.011213\n",
      "Train Epoch: 2390 \tLoss: 1.011036\n",
      "Train Epoch: 2400 \tLoss: 1.010859\n",
      "Train Epoch: 2410 \tLoss: 1.010682\n",
      "Train Epoch: 2420 \tLoss: 1.010505\n",
      "Train Epoch: 2430 \tLoss: 1.010329\n",
      "Train Epoch: 2440 \tLoss: 1.010152\n",
      "Train Epoch: 2450 \tLoss: 1.009976\n",
      "Train Epoch: 2460 \tLoss: 1.009800\n",
      "Train Epoch: 2470 \tLoss: 1.009624\n",
      "Train Epoch: 2480 \tLoss: 1.009447\n",
      "Train Epoch: 2490 \tLoss: 1.009272\n",
      "Train Epoch: 2500 \tLoss: 1.009096\n",
      "Train Epoch: 2510 \tLoss: 1.008920\n",
      "Train Epoch: 2520 \tLoss: 1.008745\n",
      "Train Epoch: 2530 \tLoss: 1.008570\n",
      "Train Epoch: 2540 \tLoss: 1.008396\n",
      "Train Epoch: 2550 \tLoss: 1.008221\n",
      "Train Epoch: 2560 \tLoss: 1.008046\n",
      "Train Epoch: 2570 \tLoss: 1.007871\n",
      "Train Epoch: 2580 \tLoss: 1.007697\n",
      "Train Epoch: 2590 \tLoss: 1.007522\n",
      "Train Epoch: 2600 \tLoss: 1.007348\n",
      "Train Epoch: 2610 \tLoss: 1.007174\n",
      "Train Epoch: 2620 \tLoss: 1.007000\n",
      "Train Epoch: 2630 \tLoss: 1.006825\n",
      "Train Epoch: 2640 \tLoss: 1.006651\n",
      "Train Epoch: 2650 \tLoss: 1.006476\n",
      "Train Epoch: 2660 \tLoss: 1.006302\n",
      "Train Epoch: 2670 \tLoss: 1.006127\n",
      "Train Epoch: 2680 \tLoss: 1.005954\n",
      "Train Epoch: 2690 \tLoss: 1.005780\n",
      "Train Epoch: 2700 \tLoss: 1.005606\n",
      "Train Epoch: 2710 \tLoss: 1.005433\n",
      "Train Epoch: 2720 \tLoss: 1.005259\n",
      "Train Epoch: 2730 \tLoss: 1.005086\n",
      "Train Epoch: 2740 \tLoss: 1.004914\n",
      "Train Epoch: 2750 \tLoss: 1.004741\n",
      "Train Epoch: 2760 \tLoss: 1.004569\n",
      "Train Epoch: 2770 \tLoss: 1.004398\n",
      "Train Epoch: 2780 \tLoss: 1.004226\n",
      "Train Epoch: 2790 \tLoss: 1.004055\n",
      "Train Epoch: 2800 \tLoss: 1.003883\n",
      "Train Epoch: 2810 \tLoss: 1.003712\n",
      "Train Epoch: 2820 \tLoss: 1.003542\n",
      "Train Epoch: 2830 \tLoss: 1.003372\n",
      "Train Epoch: 2840 \tLoss: 1.003201\n",
      "Train Epoch: 2850 \tLoss: 1.003031\n",
      "Train Epoch: 2860 \tLoss: 1.002861\n",
      "Train Epoch: 2870 \tLoss: 1.002692\n",
      "Train Epoch: 2880 \tLoss: 1.002523\n",
      "Train Epoch: 2890 \tLoss: 1.002354\n",
      "Train Epoch: 2900 \tLoss: 1.002186\n",
      "Train Epoch: 2910 \tLoss: 1.002018\n",
      "Train Epoch: 2920 \tLoss: 1.001850\n",
      "Train Epoch: 2930 \tLoss: 1.001683\n",
      "Train Epoch: 2940 \tLoss: 1.001516\n",
      "Train Epoch: 2950 \tLoss: 1.001347\n",
      "Train Epoch: 2960 \tLoss: 1.001179\n",
      "Train Epoch: 2970 \tLoss: 1.001010\n",
      "Train Epoch: 2980 \tLoss: 1.000842\n",
      "Train Epoch: 2990 \tLoss: 1.000674\n",
      "Train Epoch: 3000 \tLoss: 1.000506\n",
      "Train Epoch: 3010 \tLoss: 1.000338\n",
      "Train Epoch: 3020 \tLoss: 1.000170\n",
      "Train Epoch: 3030 \tLoss: 1.000002\n",
      "Train Epoch: 3040 \tLoss: 0.999834\n",
      "Train Epoch: 3050 \tLoss: 0.999667\n",
      "Train Epoch: 3060 \tLoss: 0.999500\n",
      "Train Epoch: 3070 \tLoss: 0.999333\n",
      "Train Epoch: 3080 \tLoss: 0.999166\n",
      "Train Epoch: 3090 \tLoss: 0.998998\n",
      "Train Epoch: 3100 \tLoss: 0.998832\n",
      "Train Epoch: 3110 \tLoss: 0.998665\n",
      "Train Epoch: 3120 \tLoss: 0.998499\n",
      "Train Epoch: 3130 \tLoss: 0.998331\n",
      "Train Epoch: 3140 \tLoss: 0.998163\n",
      "Train Epoch: 3150 \tLoss: 0.997996\n",
      "Train Epoch: 3160 \tLoss: 0.997830\n",
      "Train Epoch: 3170 \tLoss: 0.997664\n",
      "Train Epoch: 3180 \tLoss: 0.997498\n",
      "Train Epoch: 3190 \tLoss: 0.997332\n",
      "Train Epoch: 3200 \tLoss: 0.997165\n",
      "Train Epoch: 3210 \tLoss: 0.996999\n",
      "Train Epoch: 3220 \tLoss: 0.996834\n",
      "Train Epoch: 3230 \tLoss: 0.996669\n",
      "Train Epoch: 3240 \tLoss: 0.996504\n",
      "Train Epoch: 3250 \tLoss: 0.996339\n",
      "Train Epoch: 3260 \tLoss: 0.996175\n",
      "Train Epoch: 3270 \tLoss: 0.996011\n",
      "Train Epoch: 3280 \tLoss: 0.995846\n",
      "Train Epoch: 3290 \tLoss: 0.995681\n",
      "Train Epoch: 3300 \tLoss: 0.995517\n",
      "Train Epoch: 3310 \tLoss: 0.995352\n",
      "Train Epoch: 3320 \tLoss: 0.995186\n",
      "Train Epoch: 3330 \tLoss: 0.995021\n",
      "Train Epoch: 3340 \tLoss: 0.994855\n",
      "Train Epoch: 3350 \tLoss: 0.994690\n",
      "Train Epoch: 3360 \tLoss: 0.994525\n",
      "Train Epoch: 3370 \tLoss: 0.994361\n",
      "Train Epoch: 3380 \tLoss: 0.994197\n",
      "Train Epoch: 3390 \tLoss: 0.994033\n",
      "Train Epoch: 3400 \tLoss: 0.993868\n",
      "Train Epoch: 3410 \tLoss: 0.993703\n",
      "Train Epoch: 3420 \tLoss: 0.993537\n",
      "Train Epoch: 3430 \tLoss: 0.993372\n",
      "Train Epoch: 3440 \tLoss: 0.993206\n",
      "Train Epoch: 3450 \tLoss: 0.993041\n",
      "Train Epoch: 3460 \tLoss: 0.992878\n",
      "Train Epoch: 3470 \tLoss: 0.992714\n",
      "Train Epoch: 3480 \tLoss: 0.992550\n",
      "Train Epoch: 3490 \tLoss: 0.992386\n",
      "Train Epoch: 3500 \tLoss: 0.992223\n",
      "Train Epoch: 3510 \tLoss: 0.992060\n",
      "Train Epoch: 3520 \tLoss: 0.991897\n",
      "Train Epoch: 3530 \tLoss: 0.991735\n",
      "Train Epoch: 3540 \tLoss: 0.991572\n",
      "Train Epoch: 3550 \tLoss: 0.991410\n",
      "Train Epoch: 3560 \tLoss: 0.991249\n",
      "Train Epoch: 3570 \tLoss: 0.991089\n",
      "Train Epoch: 3580 \tLoss: 0.990928\n",
      "Train Epoch: 3590 \tLoss: 0.990768\n",
      "Train Epoch: 3600 \tLoss: 0.990608\n",
      "Train Epoch: 3610 \tLoss: 0.990448\n",
      "Train Epoch: 3620 \tLoss: 0.990288\n",
      "Train Epoch: 3630 \tLoss: 0.990129\n",
      "Train Epoch: 3640 \tLoss: 0.989970\n",
      "Train Epoch: 3650 \tLoss: 0.989812\n",
      "Train Epoch: 3660 \tLoss: 0.989654\n",
      "Train Epoch: 3670 \tLoss: 0.989496\n",
      "Train Epoch: 3680 \tLoss: 0.989339\n",
      "Train Epoch: 3690 \tLoss: 0.989181\n",
      "Train Epoch: 3700 \tLoss: 0.989024\n",
      "Train Epoch: 3710 \tLoss: 0.988866\n",
      "Train Epoch: 3720 \tLoss: 0.988709\n",
      "Train Epoch: 3730 \tLoss: 0.988551\n",
      "Train Epoch: 3740 \tLoss: 0.988393\n",
      "Train Epoch: 3750 \tLoss: 0.988235\n",
      "Train Epoch: 3760 \tLoss: 0.988077\n",
      "Train Epoch: 3770 \tLoss: 0.987920\n",
      "Train Epoch: 3780 \tLoss: 0.987763\n",
      "Train Epoch: 3790 \tLoss: 0.987606\n",
      "Train Epoch: 3800 \tLoss: 0.987450\n",
      "Train Epoch: 3810 \tLoss: 0.987294\n",
      "Train Epoch: 3820 \tLoss: 0.987139\n",
      "Train Epoch: 3830 \tLoss: 0.986984\n",
      "Train Epoch: 3840 \tLoss: 0.986829\n",
      "Train Epoch: 3850 \tLoss: 0.986675\n",
      "Train Epoch: 3860 \tLoss: 0.986520\n",
      "Train Epoch: 3870 \tLoss: 0.986366\n",
      "Train Epoch: 3880 \tLoss: 0.986212\n",
      "Train Epoch: 3890 \tLoss: 0.986058\n",
      "Train Epoch: 3900 \tLoss: 0.985904\n",
      "Train Epoch: 3910 \tLoss: 0.985751\n",
      "Train Epoch: 3920 \tLoss: 0.985597\n",
      "Train Epoch: 3930 \tLoss: 0.985444\n",
      "Train Epoch: 3940 \tLoss: 0.985291\n",
      "Train Epoch: 3950 \tLoss: 0.985137\n",
      "Train Epoch: 3960 \tLoss: 0.984984\n",
      "Train Epoch: 3970 \tLoss: 0.984831\n",
      "Train Epoch: 3980 \tLoss: 0.984679\n",
      "Train Epoch: 3990 \tLoss: 0.984525\n",
      "Train Epoch: 4000 \tLoss: 0.984372\n",
      "Train Epoch: 4010 \tLoss: 0.984219\n",
      "Train Epoch: 4020 \tLoss: 0.984066\n",
      "Train Epoch: 4030 \tLoss: 0.983913\n",
      "Train Epoch: 4040 \tLoss: 0.983761\n",
      "Train Epoch: 4050 \tLoss: 0.983610\n",
      "Train Epoch: 4060 \tLoss: 0.983459\n",
      "Train Epoch: 4070 \tLoss: 0.983308\n",
      "Train Epoch: 4080 \tLoss: 0.983158\n",
      "Train Epoch: 4090 \tLoss: 0.983008\n",
      "Train Epoch: 4100 \tLoss: 0.982858\n",
      "Train Epoch: 4110 \tLoss: 0.982709\n",
      "Train Epoch: 4120 \tLoss: 0.982560\n",
      "Train Epoch: 4130 \tLoss: 0.982411\n",
      "Train Epoch: 4140 \tLoss: 0.982264\n",
      "Train Epoch: 4150 \tLoss: 0.982117\n",
      "Train Epoch: 4160 \tLoss: 0.981970\n",
      "Train Epoch: 4170 \tLoss: 0.981823\n",
      "Train Epoch: 4180 \tLoss: 0.981676\n",
      "Train Epoch: 4190 \tLoss: 0.981529\n",
      "Train Epoch: 4200 \tLoss: 0.981383\n",
      "Train Epoch: 4210 \tLoss: 0.981237\n",
      "Train Epoch: 4220 \tLoss: 0.981092\n",
      "Train Epoch: 4230 \tLoss: 0.980947\n",
      "Train Epoch: 4240 \tLoss: 0.980802\n",
      "Train Epoch: 4250 \tLoss: 0.980657\n",
      "Train Epoch: 4260 \tLoss: 0.980513\n",
      "Train Epoch: 4270 \tLoss: 0.980368\n",
      "Train Epoch: 4280 \tLoss: 0.980224\n",
      "Train Epoch: 4290 \tLoss: 0.980080\n",
      "Train Epoch: 4300 \tLoss: 0.979936\n",
      "Train Epoch: 4310 \tLoss: 0.979793\n",
      "Train Epoch: 4320 \tLoss: 0.979650\n",
      "Train Epoch: 4330 \tLoss: 0.979507\n",
      "Train Epoch: 4340 \tLoss: 0.979365\n",
      "Train Epoch: 4350 \tLoss: 0.979223\n",
      "Train Epoch: 4360 \tLoss: 0.979081\n",
      "Train Epoch: 4370 \tLoss: 0.978940\n",
      "Train Epoch: 4380 \tLoss: 0.978800\n",
      "Train Epoch: 4390 \tLoss: 0.978660\n",
      "Train Epoch: 4400 \tLoss: 0.978520\n",
      "Train Epoch: 4410 \tLoss: 0.978380\n",
      "Train Epoch: 4420 \tLoss: 0.978240\n",
      "Train Epoch: 4430 \tLoss: 0.978100\n",
      "Train Epoch: 4440 \tLoss: 0.977961\n",
      "Train Epoch: 4450 \tLoss: 0.977821\n",
      "Train Epoch: 4460 \tLoss: 0.977682\n",
      "Train Epoch: 4470 \tLoss: 0.977544\n",
      "Train Epoch: 4480 \tLoss: 0.977406\n",
      "Train Epoch: 4490 \tLoss: 0.977269\n",
      "Train Epoch: 4500 \tLoss: 0.977131\n",
      "Train Epoch: 4510 \tLoss: 0.976994\n",
      "Train Epoch: 4520 \tLoss: 0.976857\n",
      "Train Epoch: 4530 \tLoss: 0.976721\n",
      "Train Epoch: 4540 \tLoss: 0.976585\n",
      "Train Epoch: 4550 \tLoss: 0.976449\n",
      "Train Epoch: 4560 \tLoss: 0.976314\n",
      "Train Epoch: 4570 \tLoss: 0.976179\n",
      "Train Epoch: 4580 \tLoss: 0.976045\n",
      "Train Epoch: 4590 \tLoss: 0.975912\n",
      "Train Epoch: 4600 \tLoss: 0.975779\n",
      "Train Epoch: 4610 \tLoss: 0.975646\n",
      "Train Epoch: 4620 \tLoss: 0.975514\n",
      "Train Epoch: 4630 \tLoss: 0.975382\n",
      "Train Epoch: 4640 \tLoss: 0.975250\n",
      "Train Epoch: 4650 \tLoss: 0.975119\n",
      "Train Epoch: 4660 \tLoss: 0.974988\n",
      "Train Epoch: 4670 \tLoss: 0.974858\n",
      "Train Epoch: 4680 \tLoss: 0.974728\n",
      "Train Epoch: 4690 \tLoss: 0.974598\n",
      "Train Epoch: 4700 \tLoss: 0.974468\n",
      "Train Epoch: 4710 \tLoss: 0.974338\n",
      "Train Epoch: 4720 \tLoss: 0.974209\n",
      "Train Epoch: 4730 \tLoss: 0.974079\n",
      "Train Epoch: 4740 \tLoss: 0.973950\n",
      "Train Epoch: 4750 \tLoss: 0.973821\n",
      "Train Epoch: 4760 \tLoss: 0.973693\n",
      "Train Epoch: 4770 \tLoss: 0.973565\n",
      "Train Epoch: 4780 \tLoss: 0.973437\n",
      "Train Epoch: 4790 \tLoss: 0.973310\n",
      "Train Epoch: 4800 \tLoss: 0.973183\n",
      "Train Epoch: 4810 \tLoss: 0.973056\n",
      "Train Epoch: 4820 \tLoss: 0.972929\n",
      "Train Epoch: 4830 \tLoss: 0.972803\n",
      "Train Epoch: 4840 \tLoss: 0.972676\n",
      "Train Epoch: 4850 \tLoss: 0.972551\n",
      "Train Epoch: 4860 \tLoss: 0.972425\n",
      "Train Epoch: 4870 \tLoss: 0.972301\n",
      "Train Epoch: 4880 \tLoss: 0.972177\n",
      "Train Epoch: 4890 \tLoss: 0.972053\n",
      "Train Epoch: 4900 \tLoss: 0.971929\n",
      "Train Epoch: 4910 \tLoss: 0.971805\n",
      "Train Epoch: 4920 \tLoss: 0.971682\n",
      "Train Epoch: 4930 \tLoss: 0.971559\n",
      "Train Epoch: 4940 \tLoss: 0.971437\n",
      "Train Epoch: 4950 \tLoss: 0.971315\n",
      "Train Epoch: 4960 \tLoss: 0.971193\n",
      "Train Epoch: 4970 \tLoss: 0.971072\n",
      "Train Epoch: 4980 \tLoss: 0.970950\n",
      "Train Epoch: 4990 \tLoss: 0.970829\n",
      "Train Epoch: 5000 \tLoss: 0.970708\n",
      "Train Epoch: 5010 \tLoss: 0.970587\n",
      "Train Epoch: 5020 \tLoss: 0.970467\n",
      "Train Epoch: 5030 \tLoss: 0.970347\n",
      "Train Epoch: 5040 \tLoss: 0.970227\n",
      "Train Epoch: 5050 \tLoss: 0.970107\n",
      "Train Epoch: 5060 \tLoss: 0.969987\n",
      "Train Epoch: 5070 \tLoss: 0.969868\n",
      "Train Epoch: 5080 \tLoss: 0.969749\n",
      "Train Epoch: 5090 \tLoss: 0.969629\n",
      "Train Epoch: 5100 \tLoss: 0.969510\n",
      "Train Epoch: 5110 \tLoss: 0.969392\n",
      "Train Epoch: 5120 \tLoss: 0.969272\n",
      "Train Epoch: 5130 \tLoss: 0.969154\n",
      "Train Epoch: 5140 \tLoss: 0.969035\n",
      "Train Epoch: 5150 \tLoss: 0.968916\n",
      "Train Epoch: 5160 \tLoss: 0.968798\n",
      "Train Epoch: 5170 \tLoss: 0.968680\n",
      "Train Epoch: 5180 \tLoss: 0.968562\n",
      "Train Epoch: 5190 \tLoss: 0.968444\n",
      "Train Epoch: 5200 \tLoss: 0.968327\n",
      "Train Epoch: 5210 \tLoss: 0.968210\n",
      "Train Epoch: 5220 \tLoss: 0.968093\n",
      "Train Epoch: 5230 \tLoss: 0.967976\n",
      "Train Epoch: 5240 \tLoss: 0.967860\n",
      "Train Epoch: 5250 \tLoss: 0.967744\n",
      "Train Epoch: 5260 \tLoss: 0.967629\n",
      "Train Epoch: 5270 \tLoss: 0.967514\n",
      "Train Epoch: 5280 \tLoss: 0.967399\n",
      "Train Epoch: 5290 \tLoss: 0.967284\n",
      "Train Epoch: 5300 \tLoss: 0.967168\n",
      "Train Epoch: 5310 \tLoss: 0.967053\n",
      "Train Epoch: 5320 \tLoss: 0.966938\n",
      "Train Epoch: 5330 \tLoss: 0.966824\n",
      "Train Epoch: 5340 \tLoss: 0.966710\n",
      "Train Epoch: 5350 \tLoss: 0.966596\n",
      "Train Epoch: 5360 \tLoss: 0.966481\n",
      "Train Epoch: 5370 \tLoss: 0.966367\n",
      "Train Epoch: 5380 \tLoss: 0.966253\n",
      "Train Epoch: 5390 \tLoss: 0.966139\n",
      "Train Epoch: 5400 \tLoss: 0.966025\n",
      "Train Epoch: 5410 \tLoss: 0.965911\n",
      "Train Epoch: 5420 \tLoss: 0.965798\n",
      "Train Epoch: 5430 \tLoss: 0.965685\n",
      "Train Epoch: 5440 \tLoss: 0.965572\n",
      "Train Epoch: 5450 \tLoss: 0.965460\n",
      "Train Epoch: 5460 \tLoss: 0.965347\n",
      "Train Epoch: 5470 \tLoss: 0.965235\n",
      "Train Epoch: 5480 \tLoss: 0.965123\n",
      "Train Epoch: 5490 \tLoss: 0.965011\n",
      "Train Epoch: 5500 \tLoss: 0.964899\n",
      "Train Epoch: 5510 \tLoss: 0.964787\n",
      "Train Epoch: 5520 \tLoss: 0.964676\n",
      "Train Epoch: 5530 \tLoss: 0.964564\n",
      "Train Epoch: 5540 \tLoss: 0.964453\n",
      "Train Epoch: 5550 \tLoss: 0.964341\n",
      "Train Epoch: 5560 \tLoss: 0.964229\n",
      "Train Epoch: 5570 \tLoss: 0.964118\n",
      "Train Epoch: 5580 \tLoss: 0.964006\n",
      "Train Epoch: 5590 \tLoss: 0.963895\n",
      "Train Epoch: 5600 \tLoss: 0.963783\n",
      "Train Epoch: 5610 \tLoss: 0.963672\n",
      "Train Epoch: 5620 \tLoss: 0.963560\n",
      "Train Epoch: 5630 \tLoss: 0.963449\n",
      "Train Epoch: 5640 \tLoss: 0.963338\n",
      "Train Epoch: 5650 \tLoss: 0.963227\n",
      "Train Epoch: 5660 \tLoss: 0.963117\n",
      "Train Epoch: 5670 \tLoss: 0.963007\n",
      "Train Epoch: 5680 \tLoss: 0.962897\n",
      "Train Epoch: 5690 \tLoss: 0.962787\n",
      "Train Epoch: 5700 \tLoss: 0.962677\n",
      "Train Epoch: 5710 \tLoss: 0.962567\n",
      "Train Epoch: 5720 \tLoss: 0.962458\n",
      "Train Epoch: 5730 \tLoss: 0.962349\n",
      "Train Epoch: 5740 \tLoss: 0.962239\n",
      "Train Epoch: 5750 \tLoss: 0.962130\n",
      "Train Epoch: 5760 \tLoss: 0.962021\n",
      "Train Epoch: 5770 \tLoss: 0.961912\n",
      "Train Epoch: 5780 \tLoss: 0.961802\n",
      "Train Epoch: 5790 \tLoss: 0.961693\n",
      "Train Epoch: 5800 \tLoss: 0.961584\n",
      "Train Epoch: 5810 \tLoss: 0.961475\n",
      "Train Epoch: 5820 \tLoss: 0.961366\n",
      "Train Epoch: 5830 \tLoss: 0.961258\n",
      "Train Epoch: 5840 \tLoss: 0.961149\n",
      "Train Epoch: 5850 \tLoss: 0.961041\n",
      "Train Epoch: 5860 \tLoss: 0.960932\n",
      "Train Epoch: 5870 \tLoss: 0.960823\n",
      "Train Epoch: 5880 \tLoss: 0.960715\n",
      "Train Epoch: 5890 \tLoss: 0.960607\n",
      "Train Epoch: 5900 \tLoss: 0.960499\n",
      "Train Epoch: 5910 \tLoss: 0.960391\n",
      "Train Epoch: 5920 \tLoss: 0.960283\n",
      "Train Epoch: 5930 \tLoss: 0.960175\n",
      "Train Epoch: 5940 \tLoss: 0.960067\n",
      "Train Epoch: 5950 \tLoss: 0.959960\n",
      "Train Epoch: 5960 \tLoss: 0.959852\n",
      "Train Epoch: 5970 \tLoss: 0.959744\n",
      "Train Epoch: 5980 \tLoss: 0.959636\n",
      "Train Epoch: 5990 \tLoss: 0.959528\n",
      "Train Epoch: 6000 \tLoss: 0.959421\n",
      "Train Epoch: 6010 \tLoss: 0.959313\n",
      "Train Epoch: 6020 \tLoss: 0.959206\n",
      "Train Epoch: 6030 \tLoss: 0.959099\n",
      "Train Epoch: 6040 \tLoss: 0.958993\n",
      "Train Epoch: 6050 \tLoss: 0.958886\n",
      "Train Epoch: 6060 \tLoss: 0.958780\n",
      "Train Epoch: 6070 \tLoss: 0.958673\n",
      "Train Epoch: 6080 \tLoss: 0.958567\n",
      "Train Epoch: 6090 \tLoss: 0.958461\n",
      "Train Epoch: 6100 \tLoss: 0.958355\n",
      "Train Epoch: 6110 \tLoss: 0.958249\n",
      "Train Epoch: 6120 \tLoss: 0.958143\n",
      "Train Epoch: 6130 \tLoss: 0.958037\n",
      "Train Epoch: 6140 \tLoss: 0.957931\n",
      "Train Epoch: 6150 \tLoss: 0.957826\n",
      "Train Epoch: 6160 \tLoss: 0.957721\n",
      "Train Epoch: 6170 \tLoss: 0.957616\n",
      "Train Epoch: 6180 \tLoss: 0.957511\n",
      "Train Epoch: 6190 \tLoss: 0.957407\n",
      "Train Epoch: 6200 \tLoss: 0.957302\n",
      "Train Epoch: 6210 \tLoss: 0.957198\n",
      "Train Epoch: 6220 \tLoss: 0.957094\n",
      "Train Epoch: 6230 \tLoss: 0.956990\n",
      "Train Epoch: 6240 \tLoss: 0.956887\n",
      "Train Epoch: 6250 \tLoss: 0.956783\n",
      "Train Epoch: 6260 \tLoss: 0.956680\n",
      "Train Epoch: 6270 \tLoss: 0.956576\n",
      "Train Epoch: 6280 \tLoss: 0.956472\n",
      "Train Epoch: 6290 \tLoss: 0.956368\n",
      "Train Epoch: 6300 \tLoss: 0.956264\n",
      "Train Epoch: 6310 \tLoss: 0.956160\n",
      "Train Epoch: 6320 \tLoss: 0.956056\n",
      "Train Epoch: 6330 \tLoss: 0.955953\n",
      "Train Epoch: 6340 \tLoss: 0.955850\n",
      "Train Epoch: 6350 \tLoss: 0.955746\n",
      "Train Epoch: 6360 \tLoss: 0.955643\n",
      "Train Epoch: 6370 \tLoss: 0.955540\n",
      "Train Epoch: 6380 \tLoss: 0.955437\n",
      "Train Epoch: 6390 \tLoss: 0.955334\n",
      "Train Epoch: 6400 \tLoss: 0.955232\n",
      "Train Epoch: 6410 \tLoss: 0.955130\n",
      "Train Epoch: 6420 \tLoss: 0.955028\n",
      "Train Epoch: 6430 \tLoss: 0.954926\n",
      "Train Epoch: 6440 \tLoss: 0.954824\n",
      "Train Epoch: 6450 \tLoss: 0.954722\n",
      "Train Epoch: 6460 \tLoss: 0.954621\n",
      "Train Epoch: 6470 \tLoss: 0.954520\n",
      "Train Epoch: 6480 \tLoss: 0.954418\n",
      "Train Epoch: 6490 \tLoss: 0.954318\n",
      "Train Epoch: 6500 \tLoss: 0.954217\n",
      "Train Epoch: 6510 \tLoss: 0.954118\n",
      "Train Epoch: 6520 \tLoss: 0.954018\n",
      "Train Epoch: 6530 \tLoss: 0.953918\n",
      "Train Epoch: 6540 \tLoss: 0.953819\n",
      "Train Epoch: 6550 \tLoss: 0.953719\n",
      "Train Epoch: 6560 \tLoss: 0.953620\n",
      "Train Epoch: 6570 \tLoss: 0.953521\n",
      "Train Epoch: 6580 \tLoss: 0.953422\n",
      "Train Epoch: 6590 \tLoss: 0.953324\n",
      "Train Epoch: 6600 \tLoss: 0.953226\n",
      "Train Epoch: 6610 \tLoss: 0.953128\n",
      "Train Epoch: 6620 \tLoss: 0.953030\n",
      "Train Epoch: 6630 \tLoss: 0.952932\n",
      "Train Epoch: 6640 \tLoss: 0.952835\n",
      "Train Epoch: 6650 \tLoss: 0.952737\n",
      "Train Epoch: 6660 \tLoss: 0.952640\n",
      "Train Epoch: 6670 \tLoss: 0.952542\n",
      "Train Epoch: 6680 \tLoss: 0.952445\n",
      "Train Epoch: 6690 \tLoss: 0.952348\n",
      "Train Epoch: 6700 \tLoss: 0.952250\n",
      "Train Epoch: 6710 \tLoss: 0.952153\n",
      "Train Epoch: 6720 \tLoss: 0.952056\n",
      "Train Epoch: 6730 \tLoss: 0.951959\n",
      "Train Epoch: 6740 \tLoss: 0.951862\n",
      "Train Epoch: 6750 \tLoss: 0.951765\n",
      "Train Epoch: 6760 \tLoss: 0.951668\n",
      "Train Epoch: 6770 \tLoss: 0.951571\n",
      "Train Epoch: 6780 \tLoss: 0.951475\n",
      "Train Epoch: 6790 \tLoss: 0.951378\n",
      "Train Epoch: 6800 \tLoss: 0.951282\n",
      "Train Epoch: 6810 \tLoss: 0.951185\n",
      "Train Epoch: 6820 \tLoss: 0.951089\n",
      "Train Epoch: 6830 \tLoss: 0.950992\n",
      "Train Epoch: 6840 \tLoss: 0.950896\n",
      "Train Epoch: 6850 \tLoss: 0.950800\n",
      "Train Epoch: 6860 \tLoss: 0.950704\n",
      "Train Epoch: 6870 \tLoss: 0.950608\n",
      "Train Epoch: 6880 \tLoss: 0.950513\n",
      "Train Epoch: 6890 \tLoss: 0.950417\n",
      "Train Epoch: 6900 \tLoss: 0.950322\n",
      "Train Epoch: 6910 \tLoss: 0.950227\n",
      "Train Epoch: 6920 \tLoss: 0.950132\n",
      "Train Epoch: 6930 \tLoss: 0.950037\n",
      "Train Epoch: 6940 \tLoss: 0.949943\n",
      "Train Epoch: 6950 \tLoss: 0.949848\n",
      "Train Epoch: 6960 \tLoss: 0.949754\n",
      "Train Epoch: 6970 \tLoss: 0.949660\n",
      "Train Epoch: 6980 \tLoss: 0.949566\n",
      "Train Epoch: 6990 \tLoss: 0.949472\n",
      "Train Epoch: 7000 \tLoss: 0.949378\n",
      "Train Epoch: 7010 \tLoss: 0.949284\n",
      "Train Epoch: 7020 \tLoss: 0.949191\n",
      "Train Epoch: 7030 \tLoss: 0.949097\n",
      "Train Epoch: 7040 \tLoss: 0.949004\n",
      "Train Epoch: 7050 \tLoss: 0.948911\n",
      "Train Epoch: 7060 \tLoss: 0.948818\n",
      "Train Epoch: 7070 \tLoss: 0.948726\n",
      "Train Epoch: 7080 \tLoss: 0.948633\n",
      "Train Epoch: 7090 \tLoss: 0.948541\n",
      "Train Epoch: 7100 \tLoss: 0.948450\n",
      "Train Epoch: 7110 \tLoss: 0.948358\n",
      "Train Epoch: 7120 \tLoss: 0.948268\n",
      "Train Epoch: 7130 \tLoss: 0.948177\n",
      "Train Epoch: 7140 \tLoss: 0.948087\n",
      "Train Epoch: 7150 \tLoss: 0.947996\n",
      "Train Epoch: 7160 \tLoss: 0.947906\n",
      "Train Epoch: 7170 \tLoss: 0.947816\n",
      "Train Epoch: 7180 \tLoss: 0.947726\n",
      "Train Epoch: 7190 \tLoss: 0.947636\n",
      "Train Epoch: 7200 \tLoss: 0.947547\n",
      "Train Epoch: 7210 \tLoss: 0.947458\n",
      "Train Epoch: 7220 \tLoss: 0.947369\n",
      "Train Epoch: 7230 \tLoss: 0.947280\n",
      "Train Epoch: 7240 \tLoss: 0.947191\n",
      "Train Epoch: 7250 \tLoss: 0.947103\n",
      "Train Epoch: 7260 \tLoss: 0.947015\n",
      "Train Epoch: 7270 \tLoss: 0.946926\n",
      "Train Epoch: 7280 \tLoss: 0.946838\n",
      "Train Epoch: 7290 \tLoss: 0.946751\n",
      "Train Epoch: 7300 \tLoss: 0.946663\n",
      "Train Epoch: 7310 \tLoss: 0.946576\n",
      "Train Epoch: 7320 \tLoss: 0.946488\n",
      "Train Epoch: 7330 \tLoss: 0.946401\n",
      "Train Epoch: 7340 \tLoss: 0.946314\n",
      "Train Epoch: 7350 \tLoss: 0.946228\n",
      "Train Epoch: 7360 \tLoss: 0.946142\n",
      "Train Epoch: 7370 \tLoss: 0.946056\n",
      "Train Epoch: 7380 \tLoss: 0.945969\n",
      "Train Epoch: 7390 \tLoss: 0.945883\n",
      "Train Epoch: 7400 \tLoss: 0.945798\n",
      "Train Epoch: 7410 \tLoss: 0.945712\n",
      "Train Epoch: 7420 \tLoss: 0.945627\n",
      "Train Epoch: 7430 \tLoss: 0.945542\n",
      "Train Epoch: 7440 \tLoss: 0.945457\n",
      "Train Epoch: 7450 \tLoss: 0.945373\n",
      "Train Epoch: 7460 \tLoss: 0.945288\n",
      "Train Epoch: 7470 \tLoss: 0.945204\n",
      "Train Epoch: 7480 \tLoss: 0.945121\n",
      "Train Epoch: 7490 \tLoss: 0.945037\n",
      "Train Epoch: 7500 \tLoss: 0.944954\n",
      "Train Epoch: 7510 \tLoss: 0.944870\n",
      "Train Epoch: 7520 \tLoss: 0.944787\n",
      "Train Epoch: 7530 \tLoss: 0.944704\n",
      "Train Epoch: 7540 \tLoss: 0.944620\n",
      "Train Epoch: 7550 \tLoss: 0.944537\n",
      "Train Epoch: 7560 \tLoss: 0.944454\n",
      "Train Epoch: 7570 \tLoss: 0.944371\n",
      "Train Epoch: 7580 \tLoss: 0.944289\n",
      "Train Epoch: 7590 \tLoss: 0.944206\n",
      "Train Epoch: 7600 \tLoss: 0.944123\n",
      "Train Epoch: 7610 \tLoss: 0.944041\n",
      "Train Epoch: 7620 \tLoss: 0.943959\n",
      "Train Epoch: 7630 \tLoss: 0.943877\n",
      "Train Epoch: 7640 \tLoss: 0.943795\n",
      "Train Epoch: 7650 \tLoss: 0.943713\n",
      "Train Epoch: 7660 \tLoss: 0.943631\n",
      "Train Epoch: 7670 \tLoss: 0.943550\n",
      "Train Epoch: 7680 \tLoss: 0.943469\n",
      "Train Epoch: 7690 \tLoss: 0.943388\n",
      "Train Epoch: 7700 \tLoss: 0.943307\n",
      "Train Epoch: 7710 \tLoss: 0.943226\n",
      "Train Epoch: 7720 \tLoss: 0.943146\n",
      "Train Epoch: 7730 \tLoss: 0.943065\n",
      "Train Epoch: 7740 \tLoss: 0.942986\n",
      "Train Epoch: 7750 \tLoss: 0.942906\n",
      "Train Epoch: 7760 \tLoss: 0.942826\n",
      "Train Epoch: 7770 \tLoss: 0.942747\n",
      "Train Epoch: 7780 \tLoss: 0.942668\n",
      "Train Epoch: 7790 \tLoss: 0.942589\n",
      "Train Epoch: 7800 \tLoss: 0.942510\n",
      "Train Epoch: 7810 \tLoss: 0.942431\n",
      "Train Epoch: 7820 \tLoss: 0.942353\n",
      "Train Epoch: 7830 \tLoss: 0.942275\n",
      "Train Epoch: 7840 \tLoss: 0.942196\n",
      "Train Epoch: 7850 \tLoss: 0.942119\n",
      "Train Epoch: 7860 \tLoss: 0.942041\n",
      "Train Epoch: 7870 \tLoss: 0.941964\n",
      "Train Epoch: 7880 \tLoss: 0.941888\n",
      "Train Epoch: 7890 \tLoss: 0.941812\n",
      "Train Epoch: 7900 \tLoss: 0.941736\n",
      "Train Epoch: 7910 \tLoss: 0.941660\n",
      "Train Epoch: 7920 \tLoss: 0.941584\n",
      "Train Epoch: 7930 \tLoss: 0.941509\n",
      "Train Epoch: 7940 \tLoss: 0.941434\n",
      "Train Epoch: 7950 \tLoss: 0.941358\n",
      "Train Epoch: 7960 \tLoss: 0.941283\n",
      "Train Epoch: 7970 \tLoss: 0.941209\n",
      "Train Epoch: 7980 \tLoss: 0.941134\n",
      "Train Epoch: 7990 \tLoss: 0.941059\n",
      "Train Epoch: 8000 \tLoss: 0.940985\n",
      "Train Epoch: 8010 \tLoss: 0.940910\n",
      "Train Epoch: 8020 \tLoss: 0.940835\n",
      "Train Epoch: 8030 \tLoss: 0.940761\n",
      "Train Epoch: 8040 \tLoss: 0.940686\n",
      "Train Epoch: 8050 \tLoss: 0.940612\n",
      "Train Epoch: 8060 \tLoss: 0.940539\n",
      "Train Epoch: 8070 \tLoss: 0.940465\n",
      "Train Epoch: 8080 \tLoss: 0.940391\n",
      "Train Epoch: 8090 \tLoss: 0.940318\n",
      "Train Epoch: 8100 \tLoss: 0.940245\n",
      "Train Epoch: 8110 \tLoss: 0.940172\n",
      "Train Epoch: 8120 \tLoss: 0.940099\n",
      "Train Epoch: 8130 \tLoss: 0.940026\n",
      "Train Epoch: 8140 \tLoss: 0.939953\n",
      "Train Epoch: 8150 \tLoss: 0.939880\n",
      "Train Epoch: 8160 \tLoss: 0.939808\n",
      "Train Epoch: 8170 \tLoss: 0.939736\n",
      "Train Epoch: 8180 \tLoss: 0.939664\n",
      "Train Epoch: 8190 \tLoss: 0.939592\n",
      "Train Epoch: 8200 \tLoss: 0.939521\n",
      "Train Epoch: 8210 \tLoss: 0.939450\n",
      "Train Epoch: 8220 \tLoss: 0.939379\n",
      "Train Epoch: 8230 \tLoss: 0.939308\n",
      "Train Epoch: 8240 \tLoss: 0.939237\n",
      "Train Epoch: 8250 \tLoss: 0.939167\n",
      "Train Epoch: 8260 \tLoss: 0.939096\n",
      "Train Epoch: 8270 \tLoss: 0.939026\n",
      "Train Epoch: 8280 \tLoss: 0.938956\n",
      "Train Epoch: 8290 \tLoss: 0.938887\n",
      "Train Epoch: 8300 \tLoss: 0.938817\n",
      "Train Epoch: 8310 \tLoss: 0.938748\n",
      "Train Epoch: 8320 \tLoss: 0.938679\n",
      "Train Epoch: 8330 \tLoss: 0.938609\n",
      "Train Epoch: 8340 \tLoss: 0.938540\n",
      "Train Epoch: 8350 \tLoss: 0.938471\n",
      "Train Epoch: 8360 \tLoss: 0.938403\n",
      "Train Epoch: 8370 \tLoss: 0.938334\n",
      "Train Epoch: 8380 \tLoss: 0.938265\n",
      "Train Epoch: 8390 \tLoss: 0.938196\n",
      "Train Epoch: 8400 \tLoss: 0.938128\n",
      "Train Epoch: 8410 \tLoss: 0.938060\n",
      "Train Epoch: 8420 \tLoss: 0.937991\n",
      "Train Epoch: 8430 \tLoss: 0.937923\n",
      "Train Epoch: 8440 \tLoss: 0.937854\n",
      "Train Epoch: 8450 \tLoss: 0.937786\n",
      "Train Epoch: 8460 \tLoss: 0.937718\n",
      "Train Epoch: 8470 \tLoss: 0.937649\n",
      "Train Epoch: 8480 \tLoss: 0.937581\n",
      "Train Epoch: 8490 \tLoss: 0.937513\n",
      "Train Epoch: 8500 \tLoss: 0.937446\n",
      "Train Epoch: 8510 \tLoss: 0.937378\n",
      "Train Epoch: 8520 \tLoss: 0.937310\n",
      "Train Epoch: 8530 \tLoss: 0.937243\n",
      "Train Epoch: 8540 \tLoss: 0.937176\n",
      "Train Epoch: 8550 \tLoss: 0.937109\n",
      "Train Epoch: 8560 \tLoss: 0.937042\n",
      "Train Epoch: 8570 \tLoss: 0.936975\n",
      "Train Epoch: 8580 \tLoss: 0.936909\n",
      "Train Epoch: 8590 \tLoss: 0.936842\n",
      "Train Epoch: 8600 \tLoss: 0.936776\n",
      "Train Epoch: 8610 \tLoss: 0.936710\n",
      "Train Epoch: 8620 \tLoss: 0.936645\n",
      "Train Epoch: 8630 \tLoss: 0.936579\n",
      "Train Epoch: 8640 \tLoss: 0.936514\n",
      "Train Epoch: 8650 \tLoss: 0.936448\n",
      "Train Epoch: 8660 \tLoss: 0.936383\n",
      "Train Epoch: 8670 \tLoss: 0.936318\n",
      "Train Epoch: 8680 \tLoss: 0.936253\n",
      "Train Epoch: 8690 \tLoss: 0.936188\n",
      "Train Epoch: 8700 \tLoss: 0.936123\n",
      "Train Epoch: 8710 \tLoss: 0.936059\n",
      "Train Epoch: 8720 \tLoss: 0.935995\n",
      "Train Epoch: 8730 \tLoss: 0.935930\n",
      "Train Epoch: 8740 \tLoss: 0.935866\n",
      "Train Epoch: 8750 \tLoss: 0.935802\n",
      "Train Epoch: 8760 \tLoss: 0.935738\n",
      "Train Epoch: 8770 \tLoss: 0.935674\n",
      "Train Epoch: 8780 \tLoss: 0.935610\n",
      "Train Epoch: 8790 \tLoss: 0.935547\n",
      "Train Epoch: 8800 \tLoss: 0.935484\n",
      "Train Epoch: 8810 \tLoss: 0.935420\n",
      "Train Epoch: 8820 \tLoss: 0.935357\n",
      "Train Epoch: 8830 \tLoss: 0.935293\n",
      "Train Epoch: 8840 \tLoss: 0.935231\n",
      "Train Epoch: 8850 \tLoss: 0.935169\n",
      "Train Epoch: 8860 \tLoss: 0.935107\n",
      "Train Epoch: 8870 \tLoss: 0.935046\n",
      "Train Epoch: 8880 \tLoss: 0.934984\n",
      "Train Epoch: 8890 \tLoss: 0.934923\n",
      "Train Epoch: 8900 \tLoss: 0.934862\n",
      "Train Epoch: 8910 \tLoss: 0.934801\n",
      "Train Epoch: 8920 \tLoss: 0.934740\n",
      "Train Epoch: 8930 \tLoss: 0.934679\n",
      "Train Epoch: 8940 \tLoss: 0.934619\n",
      "Train Epoch: 8950 \tLoss: 0.934558\n",
      "Train Epoch: 8960 \tLoss: 0.934497\n",
      "Train Epoch: 8970 \tLoss: 0.934435\n",
      "Train Epoch: 8980 \tLoss: 0.934375\n",
      "Train Epoch: 8990 \tLoss: 0.934314\n",
      "Train Epoch: 9000 \tLoss: 0.934253\n",
      "Train Epoch: 9010 \tLoss: 0.934193\n",
      "Train Epoch: 9020 \tLoss: 0.934133\n",
      "Train Epoch: 9030 \tLoss: 0.934072\n",
      "Train Epoch: 9040 \tLoss: 0.934012\n",
      "Train Epoch: 9050 \tLoss: 0.933951\n",
      "Train Epoch: 9060 \tLoss: 0.933890\n",
      "Train Epoch: 9070 \tLoss: 0.933829\n",
      "Train Epoch: 9080 \tLoss: 0.933769\n",
      "Train Epoch: 9090 \tLoss: 0.933708\n",
      "Train Epoch: 9100 \tLoss: 0.933648\n",
      "Train Epoch: 9110 \tLoss: 0.933589\n",
      "Train Epoch: 9120 \tLoss: 0.933529\n",
      "Train Epoch: 9130 \tLoss: 0.933470\n",
      "Train Epoch: 9140 \tLoss: 0.933411\n",
      "Train Epoch: 9150 \tLoss: 0.933353\n",
      "Train Epoch: 9160 \tLoss: 0.933294\n",
      "Train Epoch: 9170 \tLoss: 0.933236\n",
      "Train Epoch: 9180 \tLoss: 0.933177\n",
      "Train Epoch: 9190 \tLoss: 0.933119\n",
      "Train Epoch: 9200 \tLoss: 0.933061\n",
      "Train Epoch: 9210 \tLoss: 0.933003\n",
      "Train Epoch: 9220 \tLoss: 0.932945\n",
      "Train Epoch: 9230 \tLoss: 0.932888\n",
      "Train Epoch: 9240 \tLoss: 0.932831\n",
      "Train Epoch: 9250 \tLoss: 0.932773\n",
      "Train Epoch: 9260 \tLoss: 0.932716\n",
      "Train Epoch: 9270 \tLoss: 0.932659\n",
      "Train Epoch: 9280 \tLoss: 0.932603\n",
      "Train Epoch: 9290 \tLoss: 0.932547\n",
      "Train Epoch: 9300 \tLoss: 0.932492\n",
      "Train Epoch: 9310 \tLoss: 0.932436\n",
      "Train Epoch: 9320 \tLoss: 0.932381\n",
      "Train Epoch: 9330 \tLoss: 0.932326\n",
      "Train Epoch: 9340 \tLoss: 0.932270\n",
      "Train Epoch: 9350 \tLoss: 0.932215\n",
      "Train Epoch: 9360 \tLoss: 0.932160\n",
      "Train Epoch: 9370 \tLoss: 0.932106\n",
      "Train Epoch: 9380 \tLoss: 0.932051\n",
      "Train Epoch: 9390 \tLoss: 0.931997\n",
      "Train Epoch: 9400 \tLoss: 0.931943\n",
      "Train Epoch: 9410 \tLoss: 0.931889\n",
      "Train Epoch: 9420 \tLoss: 0.931835\n",
      "Train Epoch: 9430 \tLoss: 0.931781\n",
      "Train Epoch: 9440 \tLoss: 0.931728\n",
      "Train Epoch: 9450 \tLoss: 0.931674\n",
      "Train Epoch: 9460 \tLoss: 0.931621\n",
      "Train Epoch: 9470 \tLoss: 0.931568\n",
      "Train Epoch: 9480 \tLoss: 0.931515\n",
      "Train Epoch: 9490 \tLoss: 0.931462\n",
      "Train Epoch: 9500 \tLoss: 0.931409\n",
      "Train Epoch: 9510 \tLoss: 0.931356\n",
      "Train Epoch: 9520 \tLoss: 0.931304\n",
      "Train Epoch: 9530 \tLoss: 0.931251\n",
      "Train Epoch: 9540 \tLoss: 0.931199\n",
      "Train Epoch: 9550 \tLoss: 0.931146\n",
      "Train Epoch: 9560 \tLoss: 0.931094\n",
      "Train Epoch: 9570 \tLoss: 0.931042\n",
      "Train Epoch: 9580 \tLoss: 0.930989\n",
      "Train Epoch: 9590 \tLoss: 0.930937\n",
      "Train Epoch: 9600 \tLoss: 0.930884\n",
      "Train Epoch: 9610 \tLoss: 0.930832\n",
      "Train Epoch: 9620 \tLoss: 0.930779\n",
      "Train Epoch: 9630 \tLoss: 0.930727\n",
      "Train Epoch: 9640 \tLoss: 0.930674\n",
      "Train Epoch: 9650 \tLoss: 0.930622\n",
      "Train Epoch: 9660 \tLoss: 0.930570\n",
      "Train Epoch: 9670 \tLoss: 0.930518\n",
      "Train Epoch: 9680 \tLoss: 0.930467\n",
      "Train Epoch: 9690 \tLoss: 0.930416\n",
      "Train Epoch: 9700 \tLoss: 0.930364\n",
      "Train Epoch: 9710 \tLoss: 0.930314\n",
      "Train Epoch: 9720 \tLoss: 0.930263\n",
      "Train Epoch: 9730 \tLoss: 0.930213\n",
      "Train Epoch: 9740 \tLoss: 0.930164\n",
      "Train Epoch: 9750 \tLoss: 0.930115\n",
      "Train Epoch: 9760 \tLoss: 0.930066\n",
      "Train Epoch: 9770 \tLoss: 0.930017\n",
      "Train Epoch: 9780 \tLoss: 0.929968\n",
      "Train Epoch: 9790 \tLoss: 0.929920\n",
      "Train Epoch: 9800 \tLoss: 0.929872\n",
      "Train Epoch: 9810 \tLoss: 0.929824\n",
      "Train Epoch: 9820 \tLoss: 0.929776\n",
      "Train Epoch: 9830 \tLoss: 0.929728\n",
      "Train Epoch: 9840 \tLoss: 0.929681\n",
      "Train Epoch: 9850 \tLoss: 0.929634\n",
      "Train Epoch: 9860 \tLoss: 0.929587\n",
      "Train Epoch: 9870 \tLoss: 0.929540\n",
      "Train Epoch: 9880 \tLoss: 0.929493\n",
      "Train Epoch: 9890 \tLoss: 0.929447\n",
      "Train Epoch: 9900 \tLoss: 0.929401\n",
      "Train Epoch: 9910 \tLoss: 0.929356\n",
      "Train Epoch: 9920 \tLoss: 0.929310\n",
      "Train Epoch: 9930 \tLoss: 0.929265\n",
      "Train Epoch: 9940 \tLoss: 0.929220\n",
      "Train Epoch: 9950 \tLoss: 0.929175\n",
      "Train Epoch: 9960 \tLoss: 0.929130\n",
      "Train Epoch: 9970 \tLoss: 0.929085\n",
      "Train Epoch: 9980 \tLoss: 0.929041\n",
      "Train Epoch: 9990 \tLoss: 0.928997\n",
      "Test accuracy: 58.51%\n"
     ]
    }
   ],
   "source": [
    "# Convert your labels to long datatype\n",
    "y_train = y_train.long()\n",
    "y_test = y_test.long()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X_train)\n",
    "    loss = criterion(out, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(X_test)\n",
    "    predicted = torch.argmax(output, dim=1)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    accuracy = correct / len(y_test)\n",
    "    print('Test accuracy: {:.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
